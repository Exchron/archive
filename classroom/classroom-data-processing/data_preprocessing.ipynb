{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62b8da7",
   "metadata": {},
   "source": [
    "# KOI Data Preprocessing - Remove Unwanted Columns\n",
    "\n",
    "This notebook preprocesses the KOI (Kepler Objects of Interest) dataset by removing columns that should not be used for machine learning analysis:\n",
    "- `kepid`: Identifier column (not predictive)\n",
    "- `koi_datalink_dvr`: Link to DV report (not predictive)\n",
    "\n",
    "## Purpose:\n",
    "- Load the original KOI dataset\n",
    "- Remove identifier and link columns\n",
    "- Save the cleaned dataset for analysis\n",
    "- Provide summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3b23a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cffbda9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de90145",
   "metadata": {},
   "source": [
    "## 2. Load Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cbae2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KOI Selected Data.csv...\n",
      "Original dataset shape: (7703, 14)\n",
      "Number of rows: 7,703\n",
      "Number of columns: 14\n",
      "\n",
      "Column names in original dataset:\n",
      " 1. tid\n",
      " 2. tfopwg_disp\n",
      " 3. pl_tranmid\n",
      " 4. pl_orbper\n",
      " 5. pl_trandurh\n",
      " 6. pl_trandep\n",
      " 7. pl_rade\n",
      " 8. pl_insol\n",
      " 9. pl_eqt\n",
      "10. st_tmag\n",
      "11. st_dist\n",
      "12. st_teff\n",
      "13. st_logg\n",
      "14. st_rad\n",
      "\n",
      "First few rows of original data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>tfopwg_disp</th>\n",
       "      <th>pl_tranmid</th>\n",
       "      <th>pl_orbper</th>\n",
       "      <th>pl_trandurh</th>\n",
       "      <th>pl_trandep</th>\n",
       "      <th>pl_rade</th>\n",
       "      <th>pl_insol</th>\n",
       "      <th>pl_eqt</th>\n",
       "      <th>st_tmag</th>\n",
       "      <th>st_dist</th>\n",
       "      <th>st_teff</th>\n",
       "      <th>st_logg</th>\n",
       "      <th>st_rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50365310</td>\n",
       "      <td>FP</td>\n",
       "      <td>2.459230e+06</td>\n",
       "      <td>2.171348</td>\n",
       "      <td>2.01722</td>\n",
       "      <td>656.886099</td>\n",
       "      <td>5.818163</td>\n",
       "      <td>22601.948581</td>\n",
       "      <td>3127.204052</td>\n",
       "      <td>9.604000</td>\n",
       "      <td>485.735</td>\n",
       "      <td>10249.0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>2.16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88863718</td>\n",
       "      <td>PC</td>\n",
       "      <td>2.459988e+06</td>\n",
       "      <td>1.931646</td>\n",
       "      <td>3.16600</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>11.215400</td>\n",
       "      <td>44464.500000</td>\n",
       "      <td>4045.000000</td>\n",
       "      <td>9.423440</td>\n",
       "      <td>295.862</td>\n",
       "      <td>7070.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124709665</td>\n",
       "      <td>FP</td>\n",
       "      <td>2.459225e+06</td>\n",
       "      <td>1.867557</td>\n",
       "      <td>1.40800</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>23.752900</td>\n",
       "      <td>2860.610000</td>\n",
       "      <td>2037.000000</td>\n",
       "      <td>9.299501</td>\n",
       "      <td>943.109</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.73000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106997505</td>\n",
       "      <td>FP</td>\n",
       "      <td>2.458493e+06</td>\n",
       "      <td>2.743230</td>\n",
       "      <td>3.16700</td>\n",
       "      <td>383.410000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1177.360000</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>9.300300</td>\n",
       "      <td>7728.170</td>\n",
       "      <td>5388.5</td>\n",
       "      <td>4.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238597883</td>\n",
       "      <td>FP</td>\n",
       "      <td>2.459987e+06</td>\n",
       "      <td>3.573014</td>\n",
       "      <td>3.37000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>11.311300</td>\n",
       "      <td>54679.300000</td>\n",
       "      <td>4260.000000</td>\n",
       "      <td>9.135500</td>\n",
       "      <td>356.437</td>\n",
       "      <td>9219.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>2.15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tid tfopwg_disp    pl_tranmid  pl_orbper  pl_trandurh   pl_trandep  \\\n",
       "0   50365310          FP  2.459230e+06   2.171348      2.01722   656.886099   \n",
       "1   88863718          PC  2.459988e+06   1.931646      3.16600  1286.000000   \n",
       "2  124709665          FP  2.459225e+06   1.867557      1.40800  1500.000000   \n",
       "3  106997505          FP  2.458493e+06   2.743230      3.16700   383.410000   \n",
       "4  238597883          FP  2.459987e+06   3.573014      3.37000   755.000000   \n",
       "\n",
       "     pl_rade      pl_insol       pl_eqt   st_tmag   st_dist  st_teff  st_logg  \\\n",
       "0   5.818163  22601.948581  3127.204052  9.604000   485.735  10249.0     4.19   \n",
       "1  11.215400  44464.500000  4045.000000  9.423440   295.862   7070.0     4.03   \n",
       "2  23.752900   2860.610000  2037.000000  9.299501   943.109   8924.0      NaN   \n",
       "3        NaN   1177.360000  1631.000000  9.300300  7728.170   5388.5     4.15   \n",
       "4  11.311300  54679.300000  4260.000000  9.135500   356.437   9219.0     4.14   \n",
       "\n",
       "    st_rad  \n",
       "0  2.16986  \n",
       "1  2.01000  \n",
       "2  5.73000  \n",
       "3      NaN  \n",
       "4  2.15000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the original KOI dataset\n",
    "print(\"Loading KOI Selected Data.csv...\")\n",
    "\n",
    "# Read the CSV file, skipping the comment lines that start with '#'\n",
    "df_original = pd.read_csv('TESS Selected Data.csv', comment='#')\n",
    "\n",
    "print(f\"Original dataset shape: {df_original.shape}\")\n",
    "print(f\"Number of rows: {df_original.shape[0]:,}\")\n",
    "print(f\"Number of columns: {df_original.shape[1]}\")\n",
    "\n",
    "print(\"\\nColumn names in original dataset:\")\n",
    "for i, col in enumerate(df_original.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nFirst few rows of original data:\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925426d2",
   "metadata": {},
   "source": [
    "## 3. Identify and Remove Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d5bfa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be removed:\n",
      "✓ tid - Found in dataset\n",
      "\n",
      "Columns that will actually be removed: ['tid']\n",
      "\n",
      "Dataset shape after removing columns:\n",
      "Original: (7703, 14)\n",
      "Cleaned:  (7703, 13)\n",
      "Columns removed: 1\n",
      "\n",
      "Remaining columns: 13\n",
      " 1. tfopwg_disp\n",
      " 2. pl_tranmid\n",
      " 3. pl_orbper\n",
      " 4. pl_trandurh\n",
      " 5. pl_trandep\n",
      " 6. pl_rade\n",
      " 7. pl_insol\n",
      " 8. pl_eqt\n",
      " 9. st_tmag\n",
      "10. st_dist\n",
      "11. st_teff\n",
      "12. st_logg\n",
      "13. st_rad\n"
     ]
    }
   ],
   "source": [
    "# Define columns to remove for machine learning analysis\n",
    "columns_to_remove = ['tid']\n",
    "\n",
    "print(\"Columns to be removed:\")\n",
    "for col in columns_to_remove:\n",
    "    if col in df_original.columns:\n",
    "        print(f\"✓ {col} - Found in dataset\")\n",
    "    else:\n",
    "        print(f\"✗ {col} - NOT found in dataset\")\n",
    "\n",
    "# Check if the columns exist before removing\n",
    "existing_columns_to_remove = [col for col in columns_to_remove if col in df_original.columns]\n",
    "\n",
    "print(f\"\\nColumns that will actually be removed: {existing_columns_to_remove}\")\n",
    "\n",
    "# Remove the unwanted columns\n",
    "df_cleaned = df_original.drop(columns=existing_columns_to_remove, errors='ignore')\n",
    "\n",
    "print(f\"\\nDataset shape after removing columns:\")\n",
    "print(f\"Original: {df_original.shape}\")\n",
    "print(f\"Cleaned:  {df_cleaned.shape}\")\n",
    "print(f\"Columns removed: {df_original.shape[1] - df_cleaned.shape[1]}\")\n",
    "\n",
    "print(f\"\\nRemaining columns: {df_cleaned.shape[1]}\")\n",
    "for i, col in enumerate(df_cleaned.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c26897",
   "metadata": {},
   "source": [
    "## 4. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df1953bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY SUMMARY ===\n",
      "\n",
      "Dataset shape: (7703, 13)\n",
      "Memory usage: 1.08 MB\n",
      "\n",
      "Data types:\n",
      "float64    12\n",
      "object      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values summary:\n",
      "Columns with missing values: 8\n",
      "       Column  Missing_Count  Missing_Percent\n",
      "11    st_logg            856            11.11\n",
      "12     st_rad            507             6.58\n",
      "5     pl_rade            506             6.57\n",
      "7      pl_eqt            311             4.04\n",
      "9     st_dist            215             2.79\n",
      "6    pl_insol            176             2.28\n",
      "10    st_teff            161             2.09\n",
      "2   pl_orbper            107             1.39\n",
      "\n",
      "Cleaned dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfopwg_disp</th>\n",
       "      <th>pl_tranmid</th>\n",
       "      <th>pl_orbper</th>\n",
       "      <th>pl_trandurh</th>\n",
       "      <th>pl_trandep</th>\n",
       "      <th>pl_rade</th>\n",
       "      <th>pl_insol</th>\n",
       "      <th>pl_eqt</th>\n",
       "      <th>st_tmag</th>\n",
       "      <th>st_dist</th>\n",
       "      <th>st_teff</th>\n",
       "      <th>st_logg</th>\n",
       "      <th>st_rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FP</td>\n",
       "      <td>2.459230e+06</td>\n",
       "      <td>2.171348</td>\n",
       "      <td>2.01722</td>\n",
       "      <td>656.886099</td>\n",
       "      <td>5.818163</td>\n",
       "      <td>22601.948581</td>\n",
       "      <td>3127.204052</td>\n",
       "      <td>9.604000</td>\n",
       "      <td>485.735</td>\n",
       "      <td>10249.0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>2.16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC</td>\n",
       "      <td>2.459988e+06</td>\n",
       "      <td>1.931646</td>\n",
       "      <td>3.16600</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>11.215400</td>\n",
       "      <td>44464.500000</td>\n",
       "      <td>4045.000000</td>\n",
       "      <td>9.423440</td>\n",
       "      <td>295.862</td>\n",
       "      <td>7070.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FP</td>\n",
       "      <td>2.459225e+06</td>\n",
       "      <td>1.867557</td>\n",
       "      <td>1.40800</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>23.752900</td>\n",
       "      <td>2860.610000</td>\n",
       "      <td>2037.000000</td>\n",
       "      <td>9.299501</td>\n",
       "      <td>943.109</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.73000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FP</td>\n",
       "      <td>2.458493e+06</td>\n",
       "      <td>2.743230</td>\n",
       "      <td>3.16700</td>\n",
       "      <td>383.410000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1177.360000</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>9.300300</td>\n",
       "      <td>7728.170</td>\n",
       "      <td>5388.5</td>\n",
       "      <td>4.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FP</td>\n",
       "      <td>2.459987e+06</td>\n",
       "      <td>3.573014</td>\n",
       "      <td>3.37000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>11.311300</td>\n",
       "      <td>54679.300000</td>\n",
       "      <td>4260.000000</td>\n",
       "      <td>9.135500</td>\n",
       "      <td>356.437</td>\n",
       "      <td>9219.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>2.15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tfopwg_disp    pl_tranmid  pl_orbper  pl_trandurh   pl_trandep    pl_rade  \\\n",
       "0          FP  2.459230e+06   2.171348      2.01722   656.886099   5.818163   \n",
       "1          PC  2.459988e+06   1.931646      3.16600  1286.000000  11.215400   \n",
       "2          FP  2.459225e+06   1.867557      1.40800  1500.000000  23.752900   \n",
       "3          FP  2.458493e+06   2.743230      3.16700   383.410000        NaN   \n",
       "4          FP  2.459987e+06   3.573014      3.37000   755.000000  11.311300   \n",
       "\n",
       "       pl_insol       pl_eqt   st_tmag   st_dist  st_teff  st_logg   st_rad  \n",
       "0  22601.948581  3127.204052  9.604000   485.735  10249.0     4.19  2.16986  \n",
       "1  44464.500000  4045.000000  9.423440   295.862   7070.0     4.03  2.01000  \n",
       "2   2860.610000  2037.000000  9.299501   943.109   8924.0      NaN  5.73000  \n",
       "3   1177.360000  1631.000000  9.300300  7728.170   5388.5     4.15      NaN  \n",
       "4  54679.300000  4260.000000  9.135500   356.437   9219.0     4.14  2.15000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform basic data quality checks on the cleaned dataset\n",
    "print(\"=== DATA QUALITY SUMMARY ===\\n\")\n",
    "\n",
    "# Basic info\n",
    "print(f\"Dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"Memory usage: {df_cleaned.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Data types\n",
    "print(f\"\\nData types:\")\n",
    "print(df_cleaned.dtypes.value_counts())\n",
    "\n",
    "# Missing values\n",
    "print(f\"\\nMissing values summary:\")\n",
    "missing_count = df_cleaned.isnull().sum()\n",
    "missing_percent = (missing_count / len(df_cleaned) * 100).round(2)\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': missing_count.index,\n",
    "    'Missing_Count': missing_count.values,\n",
    "    'Missing_Percent': missing_percent.values\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "# Show only columns with missing values\n",
    "columns_with_missing = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "if len(columns_with_missing) > 0:\n",
    "    print(f\"Columns with missing values: {len(columns_with_missing)}\")\n",
    "    print(columns_with_missing)\n",
    "else:\n",
    "    print(\"No missing values found!\")\n",
    "\n",
    "# Target variable distribution\n",
    "if 'koi_disposition' in df_cleaned.columns:\n",
    "    print(f\"\\nTarget variable (koi_disposition) distribution:\")\n",
    "    disposition_counts = df_cleaned['koi_disposition'].value_counts()\n",
    "    print(disposition_counts)\n",
    "    print(f\"\\nPercentages:\")\n",
    "    print((disposition_counts / len(df_cleaned) * 100).round(2))\n",
    "\n",
    "print(f\"\\nCleaned dataset preview:\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "630a7600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with >30% missing data that will be dropped:\n",
      "\n",
      "Original shape: (7703, 13)\n",
      "New shape: (7703, 13)\n",
      "Columns removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing percentage for each column\n",
    "missing_percent = df_cleaned.isnull().sum() / len(df_cleaned) * 100\n",
    "\n",
    "# Find columns with more than 75% missing data\n",
    "high_missing_cols = missing_percent[missing_percent > 30].index.tolist()\n",
    "\n",
    "print(\"Columns with >30% missing data that will be dropped:\")\n",
    "for col in high_missing_cols:\n",
    "    print(f\"- {col}: {missing_percent[col]:.2f}% missing\")\n",
    "\n",
    "# Create new dataframe without high-missing columns\n",
    "df_cleaned_reduced = df_cleaned.drop(columns=high_missing_cols)\n",
    "\n",
    "print(f\"\\nOriginal shape: {df_cleaned.shape}\")\n",
    "print(f\"New shape: {df_cleaned_reduced.shape}\")\n",
    "print(f\"Columns removed: {len(high_missing_cols)}\")\n",
    "\n",
    "# Update the main dataframe\n",
    "df_cleaned = df_cleaned_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0ef99",
   "metadata": {},
   "source": [
    "## 5. Handle Missing Values (Non-Destructive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea9cc4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HANDLING MISSING VALUES ===\n",
      "\n",
      "Total missing values before processing: 2,839\n",
      "\n",
      "Numerical columns to process: 12\n",
      "Categorical columns to process: 1\n",
      "✓ pl_orbper: filled with median 4.09\n",
      "✓ pl_rade: filled with median 10.54\n",
      "✓ pl_insol: filled with median 363.90\n",
      "✓ pl_eqt: filled with median 1183.01\n",
      "✓ st_dist: filled with median 365.01\n",
      "✓ st_teff: filled with median 5800.55\n",
      "✓ st_logg: filled with median 4.33\n",
      "✓ st_rad: filled with median 1.23\n",
      "\n",
      "Total missing values after processing: 0\n",
      "Missing values filled: 2,839\n",
      "\n",
      "Summary of changes:\n",
      "pl_orbper: 107 → 0 missing values\n",
      "pl_rade: 506 → 0 missing values\n",
      "pl_insol: 176 → 0 missing values\n",
      "pl_eqt: 311 → 0 missing values\n",
      "st_dist: 215 → 0 missing values\n",
      "st_teff: 161 → 0 missing values\n",
      "st_logg: 856 → 0 missing values\n",
      "st_rad: 507 → 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\navid\\AppData\\Local\\Temp\\ipykernel_11460\\3283865381.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values using non-destructive methods\n",
    "print(\"=== HANDLING MISSING VALUES ===\\n\")\n",
    "\n",
    "# Create a copy for processing\n",
    "df_processed = df_cleaned.copy()\n",
    "\n",
    "# Check current missing values\n",
    "initial_missing = df_processed.isnull().sum().sum()\n",
    "print(f\"Total missing values before processing: {initial_missing:,}\")\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"\\nNumerical columns to process: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns to process: {len(categorical_cols)}\")\n",
    "\n",
    "# Strategy 1: Fill numerical missing values with median\n",
    "for col in numerical_cols:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        median_val = df_processed[col].median()\n",
    "        df_processed[col].fillna(median_val, inplace=True)\n",
    "        print(f\"✓ {col}: filled with median {median_val:.2f}\")\n",
    "\n",
    "# Strategy 2: Fill categorical missing values with mode\n",
    "for col in categorical_cols:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        mode_val = df_processed[col].mode()[0]\n",
    "        df_processed[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"✓ {col}: filled with mode '{mode_val}'\")\n",
    "\n",
    "# Special handling for astronomical data\n",
    "special_fills = {\n",
    "    'pl_orbeccen': 0.0,  # Assuming circular orbit\n",
    "    'pl_imppar': 0.5,    # Assuming average impact parameter\n",
    "}\n",
    "\n",
    "for col, fill_val in special_fills.items():\n",
    "    if col in df_processed.columns and df_processed[col].isnull().sum() > 0:\n",
    "        df_processed[col].fillna(fill_val, inplace=True)\n",
    "        print(f\"✓ {col}: filled with domain-specific value {fill_val}\")\n",
    "\n",
    "# Final check\n",
    "final_missing = df_processed.isnull().sum().sum()\n",
    "print(f\"\\nTotal missing values after processing: {final_missing:,}\")\n",
    "print(f\"Missing values filled: {initial_missing - final_missing:,}\")\n",
    "\n",
    "# Create a summary of the changes\n",
    "print(\"\\nSummary of changes:\")\n",
    "for col in df_processed.columns:\n",
    "    initial = df_cleaned[col].isnull().sum()\n",
    "    final = df_processed[col].isnull().sum()\n",
    "    if initial > 0:\n",
    "        print(f\"{col}: {initial:,} → {final:,} missing values\")\n",
    "\n",
    "# Store processed dataframe\n",
    "df_cleaned = df_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77326d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned dataset to: TESS_Cleaned_Data.csv\n",
      "✓ File saved successfully!\n",
      "  File size: 0.78 MB\n",
      "  Verification - Shape: (7703, 13)\n",
      "  Verification - Columns match: True\n",
      "\n",
      "=== PREPROCESSING COMPLETE ===\n",
      "Original dataset: 7,703 rows × 14 columns\n",
      "Cleaned dataset:  7,703 rows × 13 columns\n",
      "Columns removed:  ['tid']\n",
      "Output file:      TESS_Cleaned_Data.csv\n",
      "\n",
      "The cleaned dataset is ready for machine learning analysis!\n",
      "✓ File saved successfully!\n",
      "  File size: 0.78 MB\n",
      "  Verification - Shape: (7703, 13)\n",
      "  Verification - Columns match: True\n",
      "\n",
      "=== PREPROCESSING COMPLETE ===\n",
      "Original dataset: 7,703 rows × 14 columns\n",
      "Cleaned dataset:  7,703 rows × 13 columns\n",
      "Columns removed:  ['tid']\n",
      "Output file:      TESS_Cleaned_Data.csv\n",
      "\n",
      "The cleaned dataset is ready for machine learning analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "output_filename = 'TESS_Cleaned_Data.csv'\n",
    "\n",
    "print(f\"Saving cleaned dataset to: {output_filename}\")\n",
    "\n",
    "# Save without index to avoid adding an extra column\n",
    "df_cleaned.to_csv(output_filename, index=False)\n",
    "\n",
    "# Verify the saved file\n",
    "if os.path.exists(output_filename):\n",
    "    file_size = os.path.getsize(output_filename) / 1024**2  # Size in MB\n",
    "    print(f\"✓ File saved successfully!\")\n",
    "    print(f\"  File size: {file_size:.2f} MB\")\n",
    "    \n",
    "    # Quick verification by reading back\n",
    "    df_verify = pd.read_csv(output_filename)\n",
    "    print(f\"  Verification - Shape: {df_verify.shape}\")\n",
    "    print(f\"  Verification - Columns match: {list(df_verify.columns) == list(df_cleaned.columns)}\")\n",
    "else:\n",
    "    print(\"✗ Error: File was not saved!\")\n",
    "\n",
    "print(f\"\\n=== PREPROCESSING COMPLETE ===\")\n",
    "print(f\"Original dataset: {df_original.shape[0]:,} rows × {df_original.shape[1]} columns\")\n",
    "print(f\"Cleaned dataset:  {df_cleaned.shape[0]:,} rows × {df_cleaned.shape[1]} columns\")\n",
    "print(f\"Columns removed:  {existing_columns_to_remove}\")\n",
    "print(f\"Output file:      {output_filename}\")\n",
    "\n",
    "print(f\"\\nThe cleaned dataset is ready for machine learning analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f40462",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully:\n",
    "\n",
    "1. **Loaded** the original KOI Selected Data.csv file\n",
    "2. **Identified** and removed unwanted columns:\n",
    "   - `kepid` (identifier, not predictive)\n",
    "   - `koi_datalink_dvr` (link to DV report, not predictive)\n",
    "3. **Performed** data quality checks on the cleaned dataset\n",
    "4. **Saved** the cleaned dataset as `KOI_Cleaned_Data.csv`\n",
    "\n",
    "### Next Steps:\n",
    "- Use the cleaned dataset (`KOI_Cleaned_Data.csv`) for machine learning analysis\n",
    "- The dataset is now ready for feature importance analysis and classification tasks\n",
    "- All identifier and link columns have been removed to prevent data leakage\n",
    "\n",
    "### Files Created:\n",
    "- `KOI_Cleaned_Data.csv` - Cleaned dataset ready for ML analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
